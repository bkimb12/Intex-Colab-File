{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Finished Regression Model.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bkimb12/Intex-Colab-File/blob/main/Finished_Regression_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#  THIS REGRESSION MODEL IS NOT IMPLEMENTED ON OUR WEBSITE. HOWEVER, IT PROVIDED VALUABLE INFORMATION AS WE MADE\n",
        "#  DECISIONS REGARDING DATA USED, ALONG WITH THE IMPORTANT FEATURES TO INCLUDE AND CONSIDER IN THIS MODEL AND OTHERS.\n",
        "\n",
        "\n",
        "# make sure to install these packages before running:\n",
        "!pip install sodapy\n",
        "\n",
        "import pandas as pd\n",
        "from sodapy import Socrata\n",
        "import requests\n",
        "import json"
      ],
      "metadata": {
        "id": "oRvgvRLpUI8Q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cad9c3b6-735e-458e-c2e3-8b46212b8f4e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting sodapy\n",
            "  Downloading sodapy-2.1.0-py2.py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: requests>=2.20.0 in /usr/local/lib/python3.7/dist-packages (from sodapy) (2.23.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20.0->sodapy) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20.0->sodapy) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20.0->sodapy) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20.0->sodapy) (2021.10.8)\n",
            "Installing collected packages: sodapy\n",
            "Successfully installed sodapy-2.1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# More installs\n",
        "from sqlalchemy import create_engine\n",
        "import urllib.parse\n",
        "urllib.parse.quote_plus(\"http://aa1zdq2gijc4ui.c1dtnhbcknoc.us-east-1.rds.amazonaws.com/\")\n",
        "!pip install mysql-connector-python"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vwXGr8V1ONnH",
        "outputId": "97fbdbc2-06f1-4d6d-d8ab-e85617d9c6d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting mysql-connector-python\n",
            "  Downloading mysql_connector_python-8.0.28-cp37-cp37m-manylinux1_x86_64.whl (37.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 37.6 MB 1.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from mysql-connector-python) (3.17.3)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.0.0->mysql-connector-python) (1.15.0)\n",
            "Installing collected packages: mysql-connector-python\n",
            "Successfully installed mysql-connector-python-8.0.28\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#In this cell, we include the functions that we might need to use as we try to run our model.\n",
        "\n",
        "#Read Data\n",
        "def get_data(records = 2000):\n",
        "  import pandas as pd\n",
        "  from sodapy import Socrata\n",
        "  import requests\n",
        "  import json\n",
        "\n",
        "  # Unauthenticated client only works with public data sets. Note 'None'\n",
        "  # in place of application token, and no username or password:\n",
        "  client = Socrata(\"opendata.utah.gov\", 'GkoHUxXZ1JrjaFB0FlLHpniwf')\n",
        "\n",
        "  # First 2000 results, returned as JSON from API / converted to Python list of\n",
        "  # dictionaries by sodapy.\n",
        "  results = client.get(\"herb-zqda\", limit = records)\n",
        "\n",
        "  # Convert to pandas DataFrame\n",
        "  df = pd.DataFrame.from_records(results)\n",
        "\n",
        "  return df\n",
        "\n",
        "# Handle missing data\n",
        "\n",
        "def drop_columns_missing_data(df, percent = 0.5):\n",
        "  for col in df:\n",
        "    if (df[col].isna().sum() / len(df)) > percent:\n",
        "      df.drop(columns = [col], inplace = True)\n",
        "\n",
        "  return df"
      ],
      "metadata": {
        "id": "Fbd3kurXr0I1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#This will collect all of the data into a dataframe that we will alter below\n",
        "df_all = get_data(252500)"
      ],
      "metadata": {
        "id": "7B7PbMuotDbN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#First we set df = df_all. This helps us if we don't want to get the data from the API everytime, allowing for faster subsequent queries.\n",
        "df = df_all"
      ],
      "metadata": {
        "id": "xNhyGY0uwF5g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datetime import datetime\n",
        "\n",
        "#This creates a new column, generated from crash_datetime that shows the time of day that the crash occurred\n",
        "df['crash_time'] = pd.to_datetime(df['crash_datetime'], format='%Y-%m-%d %H:%M:%S.%f').dt.hour\n",
        "\n",
        "#This creates a new column, generated from crash_datetime that shows the day of the month that the crash occurred\n",
        "df['crash_day'] = pd.to_datetime(df['crash_datetime'], format='%Y-%m-%d %H:%M:%S.%f').dt.day\n",
        "\n",
        "#This creates a new column, generated from crash_datetime that shows the day of the week that the crash occurred\n",
        "df['crash_dayofweek'] = pd.to_datetime(df['crash_datetime'], format='%Y-%m-%d %H:%M:%S.%f').dt.dayofweek\n",
        "\n",
        "#This creates a new column, generated from crash_datetime that shows the year that the crash occurred\n",
        "df['crash_year'] = pd.to_datetime(df['crash_datetime'], format='%Y-%m-%d %H:%M:%S.%f').dt.year\n",
        "\n",
        "#This creates a new column, generated from crash_datetime that shows the month that the crash occurred\n",
        "df['crash_month'] = pd.to_datetime(df['crash_datetime'], format='%Y-%m-%d %H:%M:%S.%f').dt.month"
      ],
      "metadata": {
        "id": "Yg_pLwEZIN2D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Here we drop any columns that we won't be using as part of our classification model\n",
        "df = df.drop(columns=['main_road_name','long_utm_x','lat_utm_y','milepoint','route', 'crash_id', 'crash_day', 'crash_datetime', 'city', 'county_name'])"
      ],
      "metadata": {
        "id": "ZWrS2ryyaqO4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#The first function called drops any columns with more than 50% of it's data missing (this is not important needed here, since no columns are missing \n",
        "#that much data, but it could be useful with future datasets). The second function drops any rows in which the crash_severity_id (which will be the \n",
        "#label) is missing.\n",
        "\n",
        "df = drop_columns_missing_data(df)\n",
        "df = df.dropna(subset=['crash_severity_id'])\n",
        "df = df.dropna(subset=['work_zone_related'])"
      ],
      "metadata": {
        "id": "jl4xttloxMur"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#This is helpful to show the distrubution of crashes in the dataset by varying levels of severity\n",
        "\n",
        "df['crash_severity_id'].value_counts()"
      ],
      "metadata": {
        "id": "KFIqJMV7xkXB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "528f0d28-bdb3-4278-9d6a-b4e21c8993e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    177189\n",
              "2     43871\n",
              "3     23889\n",
              "4      4652\n",
              "5       960\n",
              "Name: crash_severity_id, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#For any other variable that has missing values (in this case it is only the work_zone_related field), this guesses the variable for that column. It\n",
        "#also creates dummy codes for the other non-numeric variables. This also changes crash severity id to a float, so we need to make sure that is changed back.\n",
        "#This is done in the next cell down\n",
        "#df = impute_mean(df, 'crash_severity_id')\n",
        "\n",
        "for col in df:\n",
        "  if not pd.api.types.is_numeric_dtype(df[col]) and col != 'crash_severity_id':\n",
        "    df = pd.get_dummies(df, columns=[col], drop_first=True)"
      ],
      "metadata": {
        "id": "T6m6qut0xOnp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Regression Model\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import statsmodels.api as sm\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "df['crash_severity_id'] = df['crash_severity_id'].astype(int)\n",
        "\n",
        "y = df['crash_severity_id']\n",
        "X = df\n",
        "#Here we drop the label and any additional columns with high p-values\n",
        "X = X.drop(columns=['crash_severity_id','night_dark_condition_True','crash_dayofweek'])\n",
        "model = sm.OLS(y, X)\n",
        "results = model.fit()\n",
        "print(results.summary())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2c2hluPAhlIn",
        "outputId": "0c35a9e0-1774-4aa6-c8c8-0237462b658a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                 OLS Regression Results                                \n",
            "=======================================================================================\n",
            "Dep. Variable:      crash_severity_id   R-squared (uncentered):                   0.818\n",
            "Model:                            OLS   Adj. R-squared (uncentered):              0.818\n",
            "Method:                 Least Squares   F-statistic:                          5.372e+04\n",
            "Date:                Fri, 08 Apr 2022   Prob (F-statistic):                        0.00\n",
            "Time:                        19:01:14   Log-Likelihood:                     -2.6440e+05\n",
            "No. Observations:              250561   AIC:                                  5.288e+05\n",
            "Df Residuals:                  250540   BIC:                                  5.291e+05\n",
            "Df Model:                          21                                                  \n",
            "Covariance Type:            nonrobust                                                  \n",
            "======================================================================================================\n",
            "                                         coef    std err          t      P>|t|      [0.025      0.975]\n",
            "------------------------------------------------------------------------------------------------------\n",
            "crash_time                             0.0015      0.000      5.623      0.000       0.001       0.002\n",
            "crash_year                             0.0006   2.54e-06    244.471      0.000       0.001       0.001\n",
            "crash_month                            0.0015      0.000      3.888      0.000       0.001       0.002\n",
            "work_zone_related_True                 0.0217      0.007      3.252      0.001       0.009       0.035\n",
            "pedestrian_involved_True               1.5220      0.013    113.301      0.000       1.496       1.548\n",
            "bicyclist_involved_True                1.3701      0.016     84.340      0.000       1.338       1.402\n",
            "motorcycle_involved_True               1.2381      0.011    114.902      0.000       1.217       1.259\n",
            "improper_restraint_True                0.3463      0.011     31.105      0.000       0.324       0.368\n",
            "unrestrained_True                      0.4932      0.009     54.661      0.000       0.475       0.511\n",
            "dui_True                               0.3434      0.008     44.118      0.000       0.328       0.359\n",
            "intersection_related_True              0.1035      0.003     34.131      0.000       0.098       0.109\n",
            "wild_animal_related_True              -0.0910      0.009    -10.203      0.000      -0.108      -0.073\n",
            "domestic_animal_related_True           0.0415      0.019      2.171      0.030       0.004       0.079\n",
            "overturn_rollover_True                 0.7556      0.008     96.616      0.000       0.740       0.771\n",
            "commercial_motor_veh_involved_True    -0.0576      0.006    -10.153      0.000      -0.069      -0.046\n",
            "teenage_driver_involved_True           0.0071      0.003      2.026      0.043       0.000       0.014\n",
            "older_driver_involved_True             0.0784      0.004     18.986      0.000       0.070       0.086\n",
            "single_vehicle_True                   -0.1464      0.006    -23.052      0.000      -0.159      -0.134\n",
            "distracted_driving_True                0.1033      0.005     21.188      0.000       0.094       0.113\n",
            "drowsy_driving_True                    0.1971      0.010     19.364      0.000       0.177       0.217\n",
            "roadway_departure_True                 0.1118      0.006     17.381      0.000       0.099       0.124\n",
            "==============================================================================\n",
            "Omnibus:                    69799.922   Durbin-Watson:                   1.994\n",
            "Prob(Omnibus):                  0.000   Jarque-Bera (JB):           171664.431\n",
            "Skew:                           1.552   Prob(JB):                         0.00\n",
            "Kurtosis:                       5.610   Cond. No.                     2.94e+04\n",
            "==============================================================================\n",
            "\n",
            "Warnings:\n",
            "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
            "[2] The condition number is large, 2.94e+04. This might indicate that there are\n",
            "strong multicollinearity or other numerical problems.\n"
          ]
        }
      ]
    }
  ]
}
